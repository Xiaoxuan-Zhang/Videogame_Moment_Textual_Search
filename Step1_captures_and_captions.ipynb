{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Preprocess Data\n",
    "\n",
    "In this step, we will preprocess game videos and captions downloaded from YouTube. The assumption for this step is that both videos and captions are available for extracting text content such as dialogues and conversations in games for textual-based search task. For the sake of simplicity, this project uses auto-cc(closed captions) which you can download using some libraries. However, extracting text content can come in different ways. For example, one can use OCR (Optical Character Recognition) techniques. OCR could be quite difficult and less accurate though. \n",
    "\n",
    "The script will do the following things:\n",
    "    1. Extract captions from vtt or xml files\n",
    "    2. Capture frames for each caption snippet\n",
    "    3. Save data and corresponding JSON file\n",
    "    4. Generate a text file including all captions extracted\n",
    "    \n",
    "Prerequisites:\n",
    "    You can download YouTube videos with auto-cc with https://rg3.github.io/youtube-dl/\n",
    "    In the command line, direct to the folder where youtube-dl.exe resides and type in the following command:\n",
    "    youtube-dl --write-auto-sub {youtube video link}\n",
    "    \n",
    "Input: \n",
    "    1. videos and captions files\n",
    "    \n",
    "Output:\n",
    "    1. A json file contains all the necessary data for the next steps\n",
    "    2. screenshots\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import webvtt as vttParser\n",
    "import subtitlexmlparser as xmlParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Make sure these variables are correctly set.\n",
    "path: the root path to where the videos and captions are located.\n",
    "output_folder: specify the path where all the outputs should be.\n",
    "game: specify the game name\n",
    "video_format: the extension of video file\n",
    "caption_format: the extension of subtitle file\n",
    "\"\"\"\n",
    "\n",
    "path = './visualization/backend/datasource/Rusty Lake/'\n",
    "output_folder = './visualization/backend/datasource/Rusty Lake/output/'\n",
    "game = 'Rusty Lake Roots'\n",
    "video_format = \"mkv\" # mp4\n",
    "caption_format = \"vtt\" # vtt\n",
    "capture_interval = 10 # n seconds of interval between captures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 100\n",
    "\n",
    "#parse time stamps in captions\n",
    "def str_to_time_seconds(timestr):\n",
    "    arr = timestr.split(':')\n",
    "    seconds = int(arr[0]) * 3600 + int(arr[1]) * 60 + float(arr[2])\n",
    "    return seconds\n",
    "    \n",
    "# print(json.dumps(blob, indent=4, sort_keys=False, separators=(',', ': ')))\n",
    "def prettify(obj):\n",
    "    print(json.dumps(obj, indent=4, sort_keys=False, separators=(',', ': ')))\n",
    "\n",
    "# convert time into frame index\n",
    "def time_to_frame(time_in_seconds, fps):\n",
    "    return int(time_in_seconds * fps)\n",
    "\n",
    "#retrieve basic information from a video file\n",
    "def parse_video_info(filename):\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "    # Check if camera opened successfully\n",
    "    if not cap.isOpened(): \n",
    "        raise Exception(\"Unable to read video file \" + filename)\n",
    "\n",
    "    # Default resolutions of the frame are obtained.The default resolutions are system dependent.\n",
    "    # We convert the resolutions from float to integer.\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    frame_per_second = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    comments = '''CV_CAP_PROP_POS_MSEC Current position of the video file in milliseconds or video capture timestamp.\n",
    "CV_CAP_PROP_POS_FRAMES 0-based index of the frame to be decoded/captured next.\n",
    "CV_CAP_PROP_POS_AVI_RATIO Relative position of the video file: 0 - start of the film, 1 - end of the film.\n",
    "CV_CAP_PROP_FRAME_WIDTH Width of the frames in the video stream.\n",
    "CV_CAP_PROP_FRAME_HEIGHT Height of the frames in the video stream.\n",
    "CV_CAP_PROP_FPS Frame rate.\n",
    "CV_CAP_PROP_FOURCC 4-character code of codec.\n",
    "CV_CAP_PROP_FRAME_COUNT Number of frames in the video file.\n",
    "CV_CAP_PROP_FORMAT Format of the Mat objects returned by retrieve() .\n",
    "CV_CAP_PROP_MODE Backend-specific value indicating the current capture mode.\n",
    "CV_CAP_PROP_BRIGHTNESS Brightness of the image (only for cameras).\n",
    "CV_CAP_PROP_CONTRAST Contrast of the image (only for cameras).\n",
    "CV_CAP_PROP_SATURATION Saturation of the image (only for cameras).\n",
    "CV_CAP_PROP_HUE Hue of the image (only for cameras).\n",
    "CV_CAP_PROP_GAIN Gain of the image (only for cameras).\n",
    "CV_CAP_PROP_EXPOSURE Exposure (only for cameras).\n",
    "CV_CAP_PROP_CONVERT_RGB Boolean flags indicating whether images should be converted to RGB.\n",
    "CV_CAP_PROP_WHITE_BALANCE Currently not supported\n",
    "CV_CAP_PROP_RECTIFICATION Rectification flag for stereo cameras (note: only supported by DC1394 v 2.x backend currently)'''\n",
    "    \n",
    "    return {'name': filename, 'capture': cap, 'frame_width': frame_width, 'frame_height': frame_height, 'frame_count': frame_count, 'frame_per_second': frame_per_second, 'total_duration': frame_count / frame_per_second}\n",
    "\n",
    "\n",
    "def laplacian_variance(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # compute the Laplacian of the image and then return the focus\n",
    "    # measure, which is simply the variance of the Laplacian\n",
    "    return cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "\n",
    "#Get frame and blur score\n",
    "def frame_blur_score(clip, frame_index):\n",
    "    cap = clip['capture']\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n",
    "    cap.grab() \n",
    "    retval, frame = cap.retrieve(0) #retrieve a frame\n",
    "    if retval:\n",
    "        blur_score = laplacian_variance(frame)   \n",
    "    else:\n",
    "        blur_score = 0.0\n",
    "    return frame, blur_score\n",
    "\n",
    "#save frame to folder\n",
    "def save_frame(frame, frame_id, folder, filename_prefix):\n",
    "    output_filename = \"%s/%s_%08d.jpg\" % (folder, filename_prefix, frame_id)\n",
    "    if os.path.isfile(output_filename):\n",
    "        # Just in case a file with the same name is already there\n",
    "        output_filename = \"%s/%s_%08d_%d.jpg\" % (folder, filename_prefix, frame_id, np.random.randint(0,100))\n",
    "    cv2.imwrite(output_filename, frame)     # save frame as JPEG file\n",
    "    return output_filename\n",
    "\n",
    "#capture frames from video source\n",
    "def capture_frames(video_info, frame_start, frame_stop, frame_step, output_folder, moment_id):\n",
    "    saved_frames = {}\n",
    "    \n",
    "    for i in range(frame_start, frame_stop, frame_step):    \n",
    "        frame_id = i\n",
    "        next_start = i + frame_step\n",
    "        blur = 0\n",
    "        offset = 5\n",
    "        # print(f'frame_start:{frame_start}, frame_stop:{frame_stop}, frame_step:{frame_step}, i: {i}')\n",
    "        #check image blur score\n",
    "        while blur < THRESHOLD:\n",
    "            frame, blur = frame_blur_score(video_info, frame_id)\n",
    "            # print(f'frame_id:{frame_id}, blur:{blur}, try next frame!')\n",
    "            if  frame_id >= frame_stop - 1 or frame_id >= frame_stop - offset or frame_id == next_start - 1:\n",
    "                # print(f'frame_id:{frame_id}, no available frame!')\n",
    "                break   \n",
    "            next_frame =  frame_id + offset # move to the next frame\n",
    "            frame_id = next_frame if next_frame < next_start else next_start - 1 # no cross boundrary\n",
    "            \n",
    "            \n",
    "        # print(f'saving frame: {frame_id}')\n",
    "        filename = save_frame(frame, frame_id, output_folder, 'Frame')\n",
    "        frame_dict = {'image_file': os.path.basename(filename)}\n",
    "        frame_dict['moment_id'] = moment_id\n",
    "        moment_id += 1\n",
    "        saved_frames[frame_id] = frame_dict\n",
    "          \n",
    "    return moment_id, saved_frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save captions and sample frames\n",
    "def process_captions(caption_file, output_folder, caption_parser = xmlParser.parse_subtitle_xml):\n",
    "    captions = caption_parser(caption_file)\n",
    "    last_text = ''\n",
    "    last_end = ''\n",
    "    last_start = ''\n",
    "    all_texts = []\n",
    "    txt_file = os.path.join(output_folder, \"caption.txt\")\n",
    "    caption_data = {'cc_file': txt_file}\n",
    "    caption_data['captions'] = {}\n",
    "    for line_id, line in enumerate(captions):\n",
    "        session_id = str(line_id)\n",
    "        text = line.text.replace(last_text, \"\").strip()\n",
    "        start = line.start.strip()\n",
    "        stop = line.end.strip()\n",
    "        caption_data['captions'][session_id] = {'timestamp_start': start, 'timestamp_stop': stop, 'text': \"\"}\n",
    "        if len(text) == 0:\n",
    "            continue   \n",
    "       \n",
    "        caption_data['captions'][session_id]['text'] = text\n",
    "        all_texts.extend(text.split(' '))\n",
    "        last_start = start\n",
    "        last_end = stop\n",
    "        last_text = text\n",
    "        \n",
    "    f = open(txt_file, \"w\")\n",
    "    f.write(' '.join(all_texts)) \n",
    "    f.close()\n",
    "    return caption_data\n",
    "\n",
    "def process_video(video_file, captions, output_folder, interval=5):\n",
    "    \n",
    "    video_info = parse_video_info(video_file) \n",
    "    frame_data = {}\n",
    "    fps = video_info['frame_per_second']\n",
    "    frame_data['image_folder'] = output_folder\n",
    "    frame_data['image_info'] = {}\n",
    "    frame_step = int(fps * interval)\n",
    "    moment_id = 0\n",
    "    for session_id, caption in captions.items():\n",
    "        frame_data['image_info'][session_id] ={}\n",
    "        time_start = str_to_time_seconds(caption['timestamp_start'])\n",
    "        time_stop = str_to_time_seconds(caption['timestamp_stop'])\n",
    "        frame_start = time_to_frame(time_start, fps)\n",
    "        frame_stop = time_to_frame(time_stop, fps)\n",
    "        frame_data['image_info'][session_id]['start'] = frame_start\n",
    "        frame_data['image_info'][session_id]['stop'] = frame_stop\n",
    "        # print(f'fps{fps}, frame_start{frame_start}, frame_stop{frame_stop}')\n",
    "        moment_id, frame_data['image_info'][session_id]['frames'] = capture_frames(video_info, frame_start, frame_stop, frame_step, output_folder, moment_id)\n",
    "    return fps, frame_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  subtitle files in total\n",
      "['./data source/Rusty Lake\\\\Roots.vtt']\n",
      "1  video files in total\n",
      "['./data source/Rusty Lake\\\\Roots.mkv']\n",
      "processing..../data source/Rusty Lake\\Roots.vtt\n",
      "processing..../data source/Rusty Lake\\Roots.mkv\n",
      "3226 screenshots captured.\n",
      "Wall time: 16min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Extract captions with screenshots\n",
    "\n",
    "if caption_format is \"xml\":\n",
    "    parser = xmlParser.parse_subtitle_xml\n",
    "else:\n",
    "    parser = vttParser.read\n",
    "    \n",
    "subtFiles = sorted(glob.glob(os.path.join(path, '*.' + caption_format)))  \n",
    "videoFiles = sorted(glob.glob(os.path.join(path, '*.' + video_format))) \n",
    "\n",
    "#subtFiles = ['./data source/Life Is Strange 1/Episode_1_Chrysalis.xml']\n",
    "#videoFiles = ['./data source/Life Is Strange 1/Episode_1_Chrysalis.mp4']\n",
    "\n",
    "print(len(subtFiles), \" subtitle files in total\");\n",
    "print(subtFiles)\n",
    "print(len(videoFiles), \" video files in total\");\n",
    "print(videoFiles)\n",
    "\n",
    "file_dict = {}  \n",
    "output_dir = ''\n",
    "\n",
    "for file_index, video_file in enumerate(videoFiles):\n",
    "    filename = os.path.basename(video_file)[:-4]  \n",
    "    output_dir = os.path.join(output_folder, filename, 'screenshots')\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    sub_file = ''\n",
    "    #find out the right subtitle file\n",
    "    for f in subtFiles:\n",
    "        if filename in os.path.basename(f)[:-4]:\n",
    "            sub_file = f\n",
    "            break;\n",
    "            \n",
    "    #Start processing\n",
    "    captions = []\n",
    "    screenshots = {}\n",
    "    print(\"processing...\" + sub_file)\n",
    "    captions = process_captions(sub_file, output_dir, caption_parser = parser)\n",
    "    print(\"processing...\" + video_file)\n",
    "    fps, screenshots = process_video(video_file, captions['captions'], output_dir, interval=capture_interval)\n",
    "    file_dict[file_index] = {}\n",
    "    file_dict[file_index]['corpus'] = filename\n",
    "    file_dict[file_index]['filename_subtitle'] = sub_file\n",
    "    file_dict[file_index]['filename_video'] = video_file\n",
    "    file_dict[file_index]['video_fps'] = fps\n",
    "    file_dict[file_index]['captions'] = captions\n",
    "    file_dict[file_index]['screenshots'] = screenshots\n",
    "\n",
    "# validate total count\n",
    "image_count = len(glob.glob(output_folder + '**/*.jpg', recursive=True));\n",
    "print(f'{image_count} screenshots captured.')\n",
    "\n",
    "#output to json file\n",
    "jsonfile_name = game.replace(\" \", \"_\")\n",
    "with open(os.path.join(output_folder, jsonfile_name + '.json'), 'w') as outfile:\n",
    "    json.dump(file_dict, outfile, sort_keys=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
